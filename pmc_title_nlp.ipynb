{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1597,
     "status": "ok",
     "timestamp": 1651453415720,
     "user": {
      "displayName": "Xingqi Zhong",
      "userId": "17073808042816522120"
     },
     "user_tz": 240
    },
    "id": "UaAMtLO-esyF"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 360534,
     "status": "ok",
     "timestamp": 1651453813468,
     "user": {
      "displayName": "Xingqi Zhong",
      "userId": "17073808042816522120"
     },
     "user_tz": 240
    },
    "id": "T-Dz1K4xesrs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KAGGLE_CONFIG_DIR\"] = \"/home/jovyan/\"\n",
    "!chmod 600 \"/home/jovyan/pmc_json.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"/home/jovyan/pmc_json.zip\",\"r\") as zf:\n",
    "    zf.extractall('ppmc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4117,
     "status": "ok",
     "timestamp": 1651453859510,
     "user": {
      "displayName": "Xingqi Zhong",
      "userId": "17073808042816522120"
     },
     "user_tz": 240
    },
    "id": "NMk7jZN6TNVF",
    "outputId": "c53e7323-a181-4a42-d9df-a7e1a3c2e596"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/spark-3.2.1-bin-hadoop3.2/python (3.2.1)\n",
      "Requirement already satisfied: py4j==0.10.9.3 in /opt/conda/lib/python3.9/site-packages (from pyspark) (0.10.9.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1651453862298,
     "user": {
      "displayName": "Xingqi Zhong",
      "userId": "17073808042816522120"
     },
     "user_tz": 240
    },
    "id": "WlhAzt8xu5ry"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.types import (\n",
    "    ArrayType,\n",
    "    IntegerType,\n",
    "    MapType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    ")\n",
    "\n",
    "\n",
    "def generate_cord19_schema():\n",
    "\n",
    "    author_fields = [\n",
    "        StructField(\"first\", StringType()),\n",
    "        StructField(\"middle\", ArrayType(StringType())),\n",
    "        StructField(\"last\", StringType()),\n",
    "        StructField(\"suffix\", StringType()),\n",
    "    ]\n",
    "\n",
    "    authors_schema = ArrayType(\n",
    "      StructType(\n",
    "          author_fields\n",
    "          + [\n",
    "              # Uncomment to cast field into a JSON string. This field is not\n",
    "              # well-specified in the source.\n",
    "              StructField(\n",
    "                  \"affiliation\",\n",
    "                  StructType(\n",
    "                      [\n",
    "                          StructField(\"laboratory\", StringType()),\n",
    "                          StructField(\"institution\", StringType()),\n",
    "                          StructField(\n",
    "                              \"location\",\n",
    "                              StructType(\n",
    "                                  [\n",
    "                                      StructField(\"settlement\", StringType()),\n",
    "                                      StructField(\"country\", StringType()),\n",
    "                                  ]\n",
    "                              ),\n",
    "                          ),\n",
    "                      ]\n",
    "                  ),\n",
    "              ),\n",
    "              StructField(\"email\", StringType()),\n",
    "          ]\n",
    "      )\n",
    "  )\n",
    "\n",
    "  # used in `section_schema` for citations, references, and equations\n",
    "    spans_schema = ArrayType(\n",
    "      StructType(\n",
    "          [\n",
    "              # character indices of inline citations\n",
    "              StructField(\"start\", IntegerType()),\n",
    "              StructField(\"end\", IntegerType()),\n",
    "              StructField(\"text\", StringType()),\n",
    "              StructField(\"ref_id\", StringType()),\n",
    "          ]\n",
    "      )\n",
    "  )\n",
    "\n",
    "  # A section of the paper, which includes the abstract, body, and back matter.\n",
    "    section_schema = ArrayType(\n",
    "      StructType(\n",
    "          [\n",
    "              StructField(\"text\", StringType()),\n",
    "              StructField(\"cite_spans\", spans_schema),\n",
    "              StructField(\"ref_spans\", spans_schema),\n",
    "              # While equations don't appear in the abstract, but appear here\n",
    "              # for consistency\n",
    "              StructField(\"eq_spans\", spans_schema),\n",
    "              StructField(\"section\", StringType()),\n",
    "          ]\n",
    "      )\n",
    "  )\n",
    "\n",
    "    bib_schema = MapType(\n",
    "      StringType(),\n",
    "      StructType(\n",
    "          [\n",
    "              StructField(\"ref_id\", StringType()),\n",
    "              StructField(\"title\", StringType()),\n",
    "              StructField(\"authors\", ArrayType(StructType(author_fields))),\n",
    "              StructField(\"year\", IntegerType()),\n",
    "              StructField(\"venue\", StringType()),\n",
    "              StructField(\"volume\", StringType()),\n",
    "              StructField(\"issn\", StringType()),\n",
    "              StructField(\"pages\", StringType()),\n",
    "              StructField(\n",
    "                  \"other_ids\",\n",
    "                  StructType([StructField(\"DOI\", ArrayType(StringType()))]),\n",
    "              ),\n",
    "          ]\n",
    "      ),\n",
    "      True,\n",
    "  )\n",
    "\n",
    "  # Can be one of table or figure captions\n",
    "    ref_schema = MapType(\n",
    "      StringType(),\n",
    "      StructType(\n",
    "          [\n",
    "              StructField(\"text\", StringType()),\n",
    "              # Likely equation spans, not included in source schema, but\n",
    "              # appears in JSON\n",
    "              StructField(\"latex\", StringType()),\n",
    "              StructField(\"type\", StringType()),\n",
    "          ]\n",
    "      ),\n",
    "  )\n",
    "\n",
    "    return StructType(\n",
    "      [\n",
    "          StructField(\"paper_id\", StringType()),\n",
    "          StructField(\n",
    "              \"metadata\",\n",
    "              StructType(\n",
    "                  [\n",
    "                      StructField(\"title\", StringType()),\n",
    "                      StructField(\"authors\", authors_schema),\n",
    "                  ]\n",
    "              ),\n",
    "              True,\n",
    "          ),\n",
    "          StructField(\"body_text\", section_schema),\n",
    "          StructField(\"bib_entries\", bib_schema),\n",
    "          StructField(\"ref_entries\", ref_schema),\n",
    "          StructField(\"back_matter\", section_schema),\n",
    "      ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 136,
     "status": "ok",
     "timestamp": 1651453865997,
     "user": {
      "displayName": "Xingqi Zhong",
      "userId": "17073808042816522120"
     },
     "user_tz": 240
    },
    "id": "Qii895m174ij"
   },
   "outputs": [],
   "source": [
    "def extract_dataframe_kaggle(spark):\n",
    "    \"\"\"Extract a structured DataFrame from the semi-structured document dump.\n",
    "\n",
    "    It should be fairly straightforward to modify this once there are new\n",
    "    documents available. The date of availability (`crawl_date`) and `source`\n",
    "    are available as metadata.\n",
    "    \"\"\"\n",
    "    base = \"ppmc/pmc_json\"\n",
    "\n",
    "    dataframe = None\n",
    "    \n",
    "    path = f\"{base}/\"\n",
    "    df = (spark.read.json(path, schema=generate_cord19_schema(), multiLine=True)\n",
    "        )\n",
    "    if not dataframe:\n",
    "        dataframe = df\n",
    "    else:\n",
    "        dataframe = dataframe.union(df)\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://e7eeff734450:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>sparkdf</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff4da32b50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "MAX_MEMORY = \"20g\"\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"sparkdf\") \\\n",
    "    .config(\"spark.executor.memory\", MAX_MEMORY) \\\n",
    "    .config(\"spark.driver.memory\", MAX_MEMORY) \\\n",
    "    .config(\"spark.memory.offHeap.enabled\",True)\\\n",
    "    .config(\"spark.memory.offHeap.size\",\"80g\")\\\n",
    "    .config(\"spark.ui.port\", \"4040\") \\\n",
    "    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 16513,
     "status": "ok",
     "timestamp": 1651453921496,
     "user": {
      "displayName": "Xingqi Zhong",
      "userId": "17073808042816522120"
     },
     "user_tz": 240
    },
    "id": "5awyjnJfNJOQ"
   },
   "outputs": [],
   "source": [
    "df = extract_dataframe_kaggle(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0xffff4c457d00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.driver.memory\",\"15g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|  paper_id|               title|\n",
      "+----------+--------------------+\n",
      "|PMC8206995|Timing of surgery...|\n",
      "|PMC7111423|     Poster Sessions|\n",
      "|PMC7122603|Cardiovascular Ac...|\n",
      "|PMC7162159|             Posters|\n",
      "|PMC7130089|             Posters|\n",
      "+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "title = (\n",
    "    df.withColumn(\"title\", F.col(\"metadata\").getField(\"title\"))\n",
    "    .select(\"paper_id\", \"title\")\n",
    ")  \n",
    "\n",
    "title.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "titlerdd = title.rdd.map(lambda row: row['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[10] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titlerdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "titlelist=[titlerdd.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperidrdd=title.select(\"paper_id\").rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperidlist=[paperidrdd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2931,
     "status": "ok",
     "timestamp": 1651444287333,
     "user": {
      "displayName": "Xiaoqing Yang",
      "userId": "17393768280237832832"
     },
     "user_tz": 240
    },
    "id": "-SpkChCnv599",
    "outputId": "515cb921-4273-44ba-d899-c0c0f1fcca49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "\n",
    "sia = SIA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 251761,
     "status": "ok",
     "timestamp": 1651444833152,
     "user": {
      "displayName": "Xiaoqing Yang",
      "userId": "17393768280237832832"
     },
     "user_tz": 240
    },
    "id": "L5Vsll9nhCYq",
    "outputId": "6c33f92c-87df-4255-f574-087532787440"
   },
   "outputs": [],
   "source": [
    "results=[]\n",
    "for lines,paperid in zip(titlelist,paperidlist):\n",
    "  \n",
    "    for line,id in zip(lines,paperid) :\n",
    "  \n",
    "        try:\n",
    "            pol_score = sia.polarity_scores(line)\n",
    "            pol_score['title'] = line\n",
    "            pol_score['paper_id']=id\n",
    "            results.append(pol_score)\n",
    "        except:\n",
    "            print('Skipped')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "iAl1niTzyqYw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_result = pd.DataFrame(results)\n",
    "\n",
    "df_result['label'] = np.zeros(len(df_result)).tolist()\n",
    "df_result.loc[df_result['compound'] > 0.05, 'label'] = 1\n",
    "df_result.loc[df_result['compound'] < -0.05 , 'label'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1651446973677,
     "user": {
      "displayName": "Xiaoqing Yang",
      "userId": "17393768280237832832"
     },
     "user_tz": 240
    },
    "id": "xNKdcy7k0wE8",
    "outputId": "e3318a10-2bd0-4b9b-93c6-f1f0fcc3a7a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0    150556\n",
       " 1.0     68399\n",
       "-1.0     67274\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result['label'].value_counts() # title_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "pqV04eeJeSYQ"
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SiqdfLSperyq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sSOes_FTerbe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xamjx1uUiG1o"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of “Copy of pmcid_text.ipynb”的副本",
   "provenance": [
    {
     "file_id": "1-0k5Fajib0d044GsNQj04DSzb4RanLLg",
     "timestamp": 1651449123302
    },
    {
     "file_id": "1zj8tuP5kblDRouhlbTIHQcrBl_LITqMU",
     "timestamp": 1651157927737
    },
    {
     "file_id": "1EgSdqWJlTcXypTUqByGAf9eL2gicrS3e",
     "timestamp": 1651021192275
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
